{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Behavior Sequence Transformer\n\nusing Transformer to capture the sequential signals underlying users' behavior sequences  \n\n### References\n- https://arxiv.org/pdf/1905.06874.pdf  \n- https://www.kaggle.com/laowingkin/netflix-movie-recommendation","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental.preprocessing import StringLookup\n\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-01-18T02:06:27.025415Z","iopub.execute_input":"2022-01-18T02:06:27.026299Z","iopub.status.idle":"2022-01-18T02:06:34.594314Z","shell.execute_reply.started":"2022-01-18T02:06:27.026187Z","shell.execute_reply":"2022-01-18T02:06:34.593548Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"# df1 = pd.read_csv('../input/netflix-prize-data/combined_data_1.txt', header=None, names=['cust_id', 'rating', 'timestamp'])\n# df1['rating'] = df1['rating'].astype(float)\n# df1.head()\n\n# df2 = pd.read_csv('../input/netflix-prize-data/combined_data_2.txt', \n#                   header=None, names=['cust_id', 'rating', 'timestamp'])\n# df2['rating'] = df2['rating'].astype(float)\n# df1 = pd.concat([df1, df2])\n# print(df1.shape)\n# del df2\n\n# df3 = pd.read_csv('../input/netflix-prize-data/combined_data_3.txt', \n#                   header=None, names=['cust_id', 'rating', 'timestamp'])\n# df3['rating'] = df3['rating'].astype(float)\n# df1 = pd.concat([df1, df3])\n# print(df1.shape)\n# del df3\n\n# df4 = pd.read_csv('../input/netflix-prize-data/combined_data_4.txt', \n#                   header=None, names=['cust_id', 'rating', 'timestamp'])\n# df4['rating'] = df4['rating'].astype(float)\n# df1 = pd.concat([df1, df4])\n# print(df1.shape)\n# del df4","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df1.to_parquet('/kaggle/working/ratings.parquet')\n# df1 = pd.read_parquet('../input/netflix-ratings/netflix_ratings.parquet')\n# df1.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_nan = df1.loc[df1['rating'].isna()].reset_index().drop(['rating', 'timestamp'], axis=1)\n# df_nan['next'] = df_nan['index'].shift(-1).fillna(df1.index[-1]+1).astype(int)\n# df_nan['movie_id'] = df_nan['cust_id'].str[:-1].astype(int)\n# df_nan.drop('cust_id', axis=1, inplace=True)\n\n# movie_ids = np.full((1, df1.shape[0]), 0)\n# for i, j, k in tqdm(df_nan[['index', 'next', 'movie_id']].values):\n#     movie_ids[0, i+1:j] = k\n# df1['movie_id'] = movie_ids[0]\n\n# df2 = df1.loc[~df1['rating'].isna()]\n# del df1, df_nan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random_selection = np.random.rand(len(df2.index)) <= 0.5\n# df3 = df2[random_selection]\n# del df2\n# df_movie_summary = df3.groupby('movie_id')[['rating']].count()\n# df_user_summary = df3.groupby('cust_id')[['rating']].count()\n# drop_movie_list = df_movie_summary.loc[df_movie_summary['rating'] < 100].index\n# drop_cust_list = df_user_summary.loc[df_user_summary['rating'] < 100].index\n\n# df3 = df3[~df3['movie_id'].isin(drop_movie_list)]\n# df3 = df3[~df3['cust_id'].isin(drop_cust_list)]\n\n\ndf3 = pd.read_parquet('../input/netflixratings/netflix_ratings_sampled01.parquet')\ndf3['cust_id'] = df3['cust_id'].apply(lambda x: f'cust_{x}')\ndf3['movie_id'] = df3['movie_id'].apply(lambda x: f'movie_{x}')\n# print('here')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-18T02:06:39.350784Z","iopub.execute_input":"2022-01-18T02:06:39.351299Z","iopub.status.idle":"2022-01-18T02:06:49.711567Z","shell.execute_reply.started":"2022-01-18T02:06:39.351252Z","shell.execute_reply":"2022-01-18T02:06:49.710722Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"ratings_group = df3.sort_values('timestamp').groupby('cust_id')\ndf3[['cust_id', 'movie_id']] = df3[['cust_id', 'movie_id']].astype('string')\nCATEGORICAL_FEATURES_WITH_VOCABULARY = {\n    'cust_id': list(df3.cust_id.unique()), \n    'movie_id': list(df3.movie_id.unique())\n}\ndel df3","metadata":{"execution":{"iopub.status.busy":"2022-01-18T02:06:49.713149Z","iopub.execute_input":"2022-01-18T02:06:49.713416Z","iopub.status.idle":"2022-01-18T02:07:10.850999Z","shell.execute_reply.started":"2022-01-18T02:06:49.713364Z","shell.execute_reply":"2022-01-18T02:07:10.850128Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"ratings_data = pd.DataFrame(data={\n    'cust_id': list(ratings_group.groups.keys()), \n    'movie_ids': list(ratings_group.movie_id.apply(list)), \n    'ratings': list(ratings_group.rating.apply(list)),\n    'timestamps': list(ratings_group.timestamp.apply(list))\n})\n\nratings_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-18T02:07:10.852509Z","iopub.execute_input":"2022-01-18T02:07:10.852773Z","iopub.status.idle":"2022-01-18T02:07:38.942556Z","shell.execute_reply.started":"2022-01-18T02:07:10.852737Z","shell.execute_reply":"2022-01-18T02:07:38.941868Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"cust_id       0\nmovie_ids     0\nratings       0\ntimestamps    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"sequence_length = 15\nstep_size = 1\n\ndef create_sequences(values, window_size, step_size):\n    sequences = []\n    start_index = 0\n    \n    while len(values[start_index:]) >= window_size:\n        end_index = start_index + window_size\n        seq = values[start_index:end_index]\n        sequences.append(seq)\n        start_index += step_size\n    return sequences\n\nratings_data.movie_ids = ratings_data.movie_ids.apply(\n    lambda ids: create_sequences(ids, sequence_length, step_size)\n)\nratings_data.ratings = ratings_data.ratings.apply(\n    lambda ids: create_sequences(ids, sequence_length, step_size)\n)\n\nratings_data.drop('timestamps', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T02:07:38.947104Z","iopub.execute_input":"2022-01-18T02:07:38.949030Z","iopub.status.idle":"2022-01-18T02:08:14.775514Z","shell.execute_reply.started":"2022-01-18T02:07:38.948991Z","shell.execute_reply":"2022-01-18T02:08:14.774706Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"ratings_data_movies = ratings_data[['cust_id', 'movie_ids']]\\\n\t\t\t\t\t\t\t\t\t\t\t\t\t.explode('movie_ids', ignore_index=True)\nratings_data_rating = ratings_data[['ratings']]\\\n\t\t\t\t\t\t\t\t\t\t\t\t\t.explode('ratings', ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T02:08:14.780111Z","iopub.execute_input":"2022-01-18T02:08:14.782181Z","iopub.status.idle":"2022-01-18T02:08:17.114497Z","shell.execute_reply.started":"2022-01-18T02:08:14.782133Z","shell.execute_reply":"2022-01-18T02:08:17.113492Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"del ratings_data\nratings_data_transformed = \\\n\t\tpd.concat([ratings_data_movies, ratings_data_rating], axis=1).dropna()\n# del ratings_data_movies, ratings_data_rating","metadata":{"execution":{"iopub.status.busy":"2022-01-18T02:08:17.117442Z","iopub.execute_input":"2022-01-18T02:08:17.118557Z","iopub.status.idle":"2022-01-18T02:08:20.485271Z","shell.execute_reply.started":"2022-01-18T02:08:17.118505Z","shell.execute_reply":"2022-01-18T02:08:20.484435Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ratings_data_transformed.movie_ids = \\\n\t\tratings_data_transformed.movie_ids\\\n\t\t.apply(lambda x: ','.join(x))\nratings_data_transformed.ratings = \\\n\t\tratings_data_transformed.ratings\\\n\t\t.apply(lambda x: ','.join([str(v) for v in x]))\nratings_data_transformed.rename(\n    columns={\"movie_ids\": \"sequence_movie_ids\", \"ratings\": \"sequence_ratings\"},\n    inplace=True,\n)\n\nrandom_selection = np.random.rand(len(ratings_data_transformed.index)) <= 0.8\ntrain_data = ratings_data_transformed[random_selection]\ntest_data = ratings_data_transformed[~random_selection]\n\n# train_data.to_parquet('/kaggle/working/train_data.parquet')\n# test_data.to_parquet('/kaggle/working/test_data.parquet')\ntrain_data.to_csv(\"/kaggle/working/train_data.csv\", index=False, sep=\"|\", header=False)\ntest_data.to_csv(\"/kaggle/working/test_data.csv\", index=False, sep=\"|\", header=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T02:08:20.486833Z","iopub.execute_input":"2022-01-18T02:08:20.487104Z","iopub.status.idle":"2022-01-18T02:09:55.209999Z","shell.execute_reply.started":"2022-01-18T02:08:20.487065Z","shell.execute_reply":"2022-01-18T02:09:55.208947Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def encode_input_features(inputs, include_user_id=True):\n    \n    encoded_transformer_features = []\n    encoded_other_features = []\n    other_feature_names = []\n    \n    if include_user_id:\n        other_feature_names.append('cust_id')\n        \n    for feature_name in other_feature_names:\n        # string input values -> integer indices\n        vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n        # nlp의 tokenizer와 비슷한 역할\n        idx = StringLookup(vocabulary=vocabulary, mask_token=None, \n                           num_oov_indices=0)(inputs[feature_name])\n        \n        embedding_dims = int(math.sqrt(len(vocabulary)))\n        embedding_encoder = layers.Embedding(\n            input_dim=len(vocabulary),\n            output_dim=embedding_dims,\n            name=f'{feature_name}_embedding'\n        )\n        \n        # convert the index values to embedding representation\n        encoded_other_features.append(embedding_encoder(idx))\n        \n    if len(encoded_other_features) == 1:\n        encoded_other_features = encoded_other_features[0]\n    else:\n        encoded_other_features = None\n        \n    #-------------------------------------#\n    # movie_id                               \n    #-------------------------------------#\n    movie_vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY['movie_id']\n    movie_embedding_dims = int(math.sqrt(len(movie_vocabulary)))\n    movie_index_lookup = StringLookup(\n        vocabulary=movie_vocabulary,\n        mask_token=None,\n        num_oov_indices=0,\n        name='movie_index_lookup'\n    )\n    \n    movie_embedding_encoder = layers.Embedding(\n        input_dim=len(movie_vocabulary),\n        output_dim=movie_embedding_dims,\n        name='movie_embedding'\n    )\n    \n    # define a function to encode a given movie id\n    def encode_movie(movie_id):\n        # string input -> integer indices\n        movie_idx = movie_index_lookup(movie_id)\n        encoded_movie = movie_embedding_encoder(movie_idx)\n        \n        return encoded_movie\n    \n    target_movie_id = inputs['target_movie_id']\n    encoded_target_movie = encode_movie(target_movie_id)\n    \n    sequence_movie_ids = inputs['sequence_movie_ids']\n    encoded_sequence_movies = encode_movie(sequence_movie_ids)\n    \n    #-------------------------------------#    \n    # position embedding\n    #-------------------------------------#\n    position_embedding_encoder = layers.Embedding(\n        input_dim=sequence_length, \n        output_dim=movie_embedding_dims, \n        name='poisition_embedding'\n    )\n    positions = tf.range(start=0, limit=sequence_length - 1, delta=1)\n    encoded_positions = position_embedding_encoder(positions)\n    \n    #-------------------------------------#\n    # ratings\n    #-------------------------------------#\n    # shape (None, 7) -> shape (None, 7, 1)  \n    sequence_ratings = tf.expand_dims(inputs['sequence_ratings'], -1)\n    \n    \n    #-------------------------------------#\n    # inner product of movie id sequence + encoded position & sequence_rating\n    #-------------------------------------#\n    \n    # encoded_sequence_movies shape (7,114)\n    # encoded_positions shape (7,114)\n    # sequence_ratings shape (None, 7, 1)\n    # encoded_sequence_movies_with_position_and_rating shape (None, 7, 114)\n    \n    encoded_sequence_movies_with_position_and_rating = layers.Multiply()(\n        [(encoded_sequence_movies + encoded_positions), sequence_ratings]\n    )\n    \n    \n    # unstack -> (None, 7, 114)에서 114씩 encoded_movie로 분리됨\n    for encoded_movie in tf.unstack(encoded_sequence_movies_with_position_and_rating, axis=1):\n        # encoded_movie shape(None, 114) -> (None, 1, 114)\n        encoded_transformer_features.append(tf.expand_dims(encoded_movie, 1))\n    \n    encoded_transformer_features.append(encoded_target_movie)\n    encoded_transformer_features = layers.concatenate(encoded_transformer_features, axis=1)\n    \n    return encoded_transformer_features, encoded_other_features","metadata":{"execution":{"iopub.status.busy":"2022-01-18T02:00:43.482182Z","iopub.execute_input":"2022-01-18T02:00:43.482464Z","iopub.status.idle":"2022-01-18T02:00:43.496342Z","shell.execute_reply.started":"2022-01-18T02:00:43.482433Z","shell.execute_reply":"2022-01-18T02:00:43.495543Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"transformer_features, other_features = encode_input_features(\n    inputs, include_user_id\n)\n\n# create a multi-headed attention layer\n# params: (target, source)\nattention_output = layers.MultiHeadAttention(\n    num_heads=num_heads, \n    key_dim=transformer_features.shape[2], \n    dropout=dropout_rate\n)(transformer_features, transformer_features)\n\n# transformer block\nattention_output = layers.Dropout(dropout_rate)(attention_output)\nx1 = layers.Add()([transformer_features, attention_output])\nx1 = layers.LayerNormalization()(x1)\nx2 = layers.LeakyReLU()(x1)\n# 왜 shape[-1]인가\nx2 = layers.Dense(units=x2.shape[-1])(x2)\nx2 = layers.Dropout(dropout_rate)(x2)\ntransformer_features = layers.Add()([x1, x2])\ntransformer_features = layers.LayerNormalization()(transformer_features)\nfeatures = layers.Flatten()(transformer_features)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:41:24.489299Z","iopub.execute_input":"2022-01-18T00:41:24.489763Z","iopub.status.idle":"2022-01-18T00:41:26.652310Z","shell.execute_reply.started":"2022-01-18T00:41:24.489724Z","shell.execute_reply":"2022-01-18T00:41:26.651635Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"if other_features is not None:\n    features = layers.concatenate(\n        [features, layers.Reshape([other_features.shape[-1]])(other_features)]\n    )\n\nfor num_units in hidden_units:\n    features = layers.Dense(num_units)(features)\n    features = layers.BatchNormalization()(features)\n    features = layers.LeakyReLU()(features)\n    features = layers.Dropout(dropout_rate)(features)\n    \noutputs = layers.Dense(units=1)(features)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n# model.compile(\n#     optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01),\n#     loss=tf.keras.losses.MeanSquaredError(),\n#     metrics=[tf.keras.metrics.MeanAbsoluteError()]\n# )\n\nmodel.compile(\n    optimizer='adam', \n    loss=tf.keras.losses.MeanSquaredError(), \n    metrics=['accuracy', tf.keras.metrics.MeanAbsoluteError()]\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T02:00:45.344817Z","iopub.execute_input":"2022-01-18T02:00:45.345062Z","iopub.status.idle":"2022-01-18T02:00:45.433860Z","shell.execute_reply.started":"2022-01-18T02:00:45.345035Z","shell.execute_reply":"2022-01-18T02:00:45.432425Z"},"trusted":true},"execution_count":31,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/3517759712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# model.compile(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 193\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    982\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 7), dtype=tf.string, name='sequence_movie_ids'), name='sequence_movie_ids', description=\"created by layer 'sequence_movie_ids'\") at layer \"movie_index_lookup\". The following previous layers were accessed without issue: []"],"ename":"ValueError","evalue":"Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 7), dtype=tf.string, name='sequence_movie_ids'), name='sequence_movie_ids', description=\"created by layer 'sequence_movie_ids'\") at layer \"movie_index_lookup\". The following previous layers were accessed without issue: []","output_type":"error"}]},{"cell_type":"code","source":"pd.read_csv('train_data.csv', sep='|', header=None).head(20)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:53:22.901655Z","iopub.execute_input":"2022-01-18T00:53:22.902179Z","iopub.status.idle":"2022-01-18T00:53:33.328958Z","shell.execute_reply.started":"2022-01-18T00:53:22.902117Z","shell.execute_reply":"2022-01-18T00:53:33.328220Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"          0                                                  1  \\\n0   cust_10  movie_6029,movie_15578,movie_5287,movie_10808,...   \n1   cust_10  movie_15578,movie_5287,movie_10808,movie_7364,...   \n2   cust_10  movie_10808,movie_7364,movie_8904,movie_4577,m...   \n3   cust_10  movie_7364,movie_8904,movie_4577,movie_17628,m...   \n4   cust_10  movie_4577,movie_17628,movie_5708,movie_2037,m...   \n5   cust_10  movie_17628,movie_5708,movie_2037,movie_5926,m...   \n6   cust_10  movie_2037,movie_5926,movie_16459,movie_6122,m...   \n7   cust_10  movie_16459,movie_6122,movie_191,movie_3962,mo...   \n8   cust_10  movie_6122,movie_191,movie_3962,movie_5293,mov...   \n9   cust_10  movie_191,movie_3962,movie_5293,movie_3623,mov...   \n10  cust_10  movie_3962,movie_5293,movie_3623,movie_7237,mo...   \n11  cust_10  movie_5293,movie_3623,movie_7237,movie_14909,m...   \n12  cust_10  movie_7237,movie_14909,movie_5181,movie_16452,...   \n13  cust_10  movie_14909,movie_5181,movie_16452,movie_11149...   \n14  cust_10  movie_5181,movie_16452,movie_11149,movie_5793,...   \n15  cust_10  movie_16452,movie_11149,movie_5793,movie_1816,...   \n16  cust_10  movie_11149,movie_5793,movie_1816,movie_12703,...   \n17  cust_10  movie_1816,movie_12703,movie_14725,movie_14999...   \n18  cust_10  movie_12703,movie_14725,movie_14999,movie_197,...   \n19  cust_10  movie_14999,movie_197,movie_11251,movie_10042,...   \n\n                                  2  \n0   3.0,5.0,4.0,4.0,4.0,4.0,4.0,1.0  \n1   5.0,4.0,4.0,4.0,4.0,4.0,1.0,3.0  \n2   4.0,4.0,4.0,4.0,1.0,3.0,4.0,4.0  \n3   4.0,4.0,4.0,1.0,3.0,4.0,4.0,3.0  \n4   4.0,1.0,3.0,4.0,4.0,3.0,3.0,4.0  \n5   1.0,3.0,4.0,4.0,3.0,3.0,4.0,5.0  \n6   4.0,4.0,3.0,3.0,4.0,5.0,3.0,2.0  \n7   3.0,3.0,4.0,5.0,3.0,2.0,4.0,4.0  \n8   3.0,4.0,5.0,3.0,2.0,4.0,4.0,5.0  \n9   4.0,5.0,3.0,2.0,4.0,4.0,5.0,4.0  \n10  5.0,3.0,2.0,4.0,4.0,5.0,4.0,3.0  \n11  3.0,2.0,4.0,4.0,5.0,4.0,3.0,3.0  \n12  4.0,4.0,5.0,4.0,3.0,3.0,2.0,2.0  \n13  4.0,5.0,4.0,3.0,3.0,2.0,2.0,5.0  \n14  5.0,4.0,3.0,3.0,2.0,2.0,5.0,2.0  \n15  4.0,3.0,3.0,2.0,2.0,5.0,2.0,4.0  \n16  3.0,3.0,2.0,2.0,5.0,2.0,4.0,3.0  \n17  2.0,2.0,5.0,2.0,4.0,3.0,4.0,3.0  \n18  2.0,5.0,2.0,4.0,3.0,4.0,3.0,4.0  \n19  2.0,4.0,3.0,4.0,3.0,4.0,3.0,3.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cust_10</td>\n      <td>movie_6029,movie_15578,movie_5287,movie_10808,...</td>\n      <td>3.0,5.0,4.0,4.0,4.0,4.0,4.0,1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cust_10</td>\n      <td>movie_15578,movie_5287,movie_10808,movie_7364,...</td>\n      <td>5.0,4.0,4.0,4.0,4.0,4.0,1.0,3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cust_10</td>\n      <td>movie_10808,movie_7364,movie_8904,movie_4577,m...</td>\n      <td>4.0,4.0,4.0,4.0,1.0,3.0,4.0,4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cust_10</td>\n      <td>movie_7364,movie_8904,movie_4577,movie_17628,m...</td>\n      <td>4.0,4.0,4.0,1.0,3.0,4.0,4.0,3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cust_10</td>\n      <td>movie_4577,movie_17628,movie_5708,movie_2037,m...</td>\n      <td>4.0,1.0,3.0,4.0,4.0,3.0,3.0,4.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>cust_10</td>\n      <td>movie_17628,movie_5708,movie_2037,movie_5926,m...</td>\n      <td>1.0,3.0,4.0,4.0,3.0,3.0,4.0,5.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>cust_10</td>\n      <td>movie_2037,movie_5926,movie_16459,movie_6122,m...</td>\n      <td>4.0,4.0,3.0,3.0,4.0,5.0,3.0,2.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>cust_10</td>\n      <td>movie_16459,movie_6122,movie_191,movie_3962,mo...</td>\n      <td>3.0,3.0,4.0,5.0,3.0,2.0,4.0,4.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>cust_10</td>\n      <td>movie_6122,movie_191,movie_3962,movie_5293,mov...</td>\n      <td>3.0,4.0,5.0,3.0,2.0,4.0,4.0,5.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>cust_10</td>\n      <td>movie_191,movie_3962,movie_5293,movie_3623,mov...</td>\n      <td>4.0,5.0,3.0,2.0,4.0,4.0,5.0,4.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>cust_10</td>\n      <td>movie_3962,movie_5293,movie_3623,movie_7237,mo...</td>\n      <td>5.0,3.0,2.0,4.0,4.0,5.0,4.0,3.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>cust_10</td>\n      <td>movie_5293,movie_3623,movie_7237,movie_14909,m...</td>\n      <td>3.0,2.0,4.0,4.0,5.0,4.0,3.0,3.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>cust_10</td>\n      <td>movie_7237,movie_14909,movie_5181,movie_16452,...</td>\n      <td>4.0,4.0,5.0,4.0,3.0,3.0,2.0,2.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>cust_10</td>\n      <td>movie_14909,movie_5181,movie_16452,movie_11149...</td>\n      <td>4.0,5.0,4.0,3.0,3.0,2.0,2.0,5.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>cust_10</td>\n      <td>movie_5181,movie_16452,movie_11149,movie_5793,...</td>\n      <td>5.0,4.0,3.0,3.0,2.0,2.0,5.0,2.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>cust_10</td>\n      <td>movie_16452,movie_11149,movie_5793,movie_1816,...</td>\n      <td>4.0,3.0,3.0,2.0,2.0,5.0,2.0,4.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>cust_10</td>\n      <td>movie_11149,movie_5793,movie_1816,movie_12703,...</td>\n      <td>3.0,3.0,2.0,2.0,5.0,2.0,4.0,3.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>cust_10</td>\n      <td>movie_1816,movie_12703,movie_14725,movie_14999...</td>\n      <td>2.0,2.0,5.0,2.0,4.0,3.0,4.0,3.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>cust_10</td>\n      <td>movie_12703,movie_14725,movie_14999,movie_197,...</td>\n      <td>2.0,5.0,2.0,4.0,3.0,4.0,3.0,4.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>cust_10</td>\n      <td>movie_14999,movie_197,movie_11251,movie_10042,...</td>\n      <td>2.0,4.0,3.0,4.0,3.0,4.0,3.0,3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = get_dataset_from_csv('train_data.csv', shuffle=True, batch_size=1024)\nmodel.fit(train_dataset, epochs=16)\n\ntest_dataset = get_dataset_from_csv('test_data.csv', batch_size=1024)\n_, mae = model.evaluate(test_dataset, verbose=0)\nprint(f'Test MAE: {round(mae, 3)}')","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:54:57.324005Z","iopub.execute_input":"2022-01-18T00:54:57.324700Z","iopub.status.idle":"2022-01-18T01:47:25.837216Z","shell.execute_reply.started":"2022-01-18T00:54:57.324655Z","shell.execute_reply":"2022-01-18T01:47:25.836312Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/16\n5118/5118 [==============================] - 158s 30ms/step - loss: 1.0570 - accuracy: 0.0408 - mean_absolute_error: 0.8070\nEpoch 2/16\n5118/5118 [==============================] - 149s 29ms/step - loss: 0.8670 - accuracy: 0.0409 - mean_absolute_error: 0.7364\nEpoch 3/16\n5118/5118 [==============================] - 149s 29ms/step - loss: 0.8341 - accuracy: 0.0409 - mean_absolute_error: 0.7216\nEpoch 4/16\n5118/5118 [==============================] - 150s 29ms/step - loss: 0.8180 - accuracy: 0.0409 - mean_absolute_error: 0.7141\nEpoch 5/16\n5118/5118 [==============================] - 151s 29ms/step - loss: 0.8060 - accuracy: 0.0409 - mean_absolute_error: 0.7088\nEpoch 6/16\n5118/5118 [==============================] - 151s 29ms/step - loss: 0.7969 - accuracy: 0.0409 - mean_absolute_error: 0.7046\nEpoch 7/16\n5118/5118 [==============================] - 151s 29ms/step - loss: 0.7898 - accuracy: 0.0409 - mean_absolute_error: 0.7016\nEpoch 8/16\n5118/5118 [==============================] - 149s 29ms/step - loss: 0.7836 - accuracy: 0.0409 - mean_absolute_error: 0.6987\nEpoch 9/16\n5118/5118 [==============================] - 153s 30ms/step - loss: 0.7781 - accuracy: 0.0409 - mean_absolute_error: 0.6963\nEpoch 10/16\n5118/5118 [==============================] - 148s 29ms/step - loss: 0.7735 - accuracy: 0.0409 - mean_absolute_error: 0.6941\nEpoch 11/16\n5118/5118 [==============================] - 148s 29ms/step - loss: 0.7695 - accuracy: 0.0409 - mean_absolute_error: 0.6924\nEpoch 12/16\n5118/5118 [==============================] - 149s 29ms/step - loss: 0.7657 - accuracy: 0.0409 - mean_absolute_error: 0.6907\nEpoch 13/16\n5118/5118 [==============================] - 151s 29ms/step - loss: 0.7622 - accuracy: 0.0409 - mean_absolute_error: 0.6890\nEpoch 14/16\n5118/5118 [==============================] - 152s 30ms/step - loss: 0.7590 - accuracy: 0.0409 - mean_absolute_error: 0.6875\nEpoch 15/16\n5118/5118 [==============================] - 149s 29ms/step - loss: 0.7558 - accuracy: 0.0409 - mean_absolute_error: 0.6861\nEpoch 16/16\n5118/5118 [==============================] - 149s 29ms/step - loss: 0.7530 - accuracy: 0.0409 - mean_absolute_error: 0.6848\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/1648059548.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset_from_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test MAE: {round(mae, 3)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"],"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error"}]},{"cell_type":"code","source":"tmp = model.evaluate(test_dataset, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T01:47:43.954339Z","iopub.execute_input":"2022-01-18T01:47:43.954893Z","iopub.status.idle":"2022-01-18T01:48:04.508185Z","shell.execute_reply.started":"2022-01-18T01:47:43.954855Z","shell.execute_reply":"2022-01-18T01:48:04.507431Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tmp","metadata":{"execution":{"iopub.status.busy":"2022-01-18T01:48:11.357972Z","iopub.execute_input":"2022-01-18T01:48:11.358813Z","iopub.status.idle":"2022-01-18T01:48:11.364046Z","shell.execute_reply.started":"2022-01-18T01:48:11.358767Z","shell.execute_reply":"2022-01-18T01:48:11.363414Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[0.8630034923553467, 0.04096076637506485, 0.7349212765693665]"},"metadata":{}}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/netflix-prize-data/movie_titles.csv', encoding=\"ISO-8859-1\", header=None, \n                 names=['Movie_Id', 'Year', 'Name'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-18T00:23:52.606216Z","iopub.execute_input":"2022-01-18T00:23:52.606566Z","iopub.status.idle":"2022-01-18T00:23:52.665779Z","shell.execute_reply.started":"2022-01-18T00:23:52.606528Z","shell.execute_reply":"2022-01-18T00:23:52.665094Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Movie_Id    Year                          Name\n0         1  2003.0               Dinosaur Planet\n1         2  2004.0    Isle of Man TT 2004 Review\n2         3  1997.0                     Character\n3         4  1994.0  Paula Abdul's Get Up & Dance\n4         5  2004.0      The Rise and Fall of ECW","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Movie_Id</th>\n      <th>Year</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2003.0</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2004.0</td>\n      <td>Isle of Man TT 2004 Review</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1997.0</td>\n      <td>Character</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1994.0</td>\n      <td>Paula Abdul's Get Up &amp; Dance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2004.0</td>\n      <td>The Rise and Fall of ECW</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}